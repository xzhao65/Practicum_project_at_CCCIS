{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "import datetime\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load JSON function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadJson(path):\n",
    "    with open(path,'r') as fp: \n",
    "        data_json = json.load(fp)\n",
    "        return (data_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data Frame function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveDataFrame(df,path):\n",
    "    '''save DataFerame in csv format'''\n",
    "    df.to_csv(path,sep=',',index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON log to Data Frame function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getData(l):\n",
    "    instance = []\n",
    "    usage = []\n",
    "    timestamps = []\n",
    "    \n",
    "    for t in l:\n",
    "        if t != []:\n",
    "            idata = t[0]\n",
    "            for h in (idata['datapoints']):\n",
    "                target = idata['target']\n",
    "                target = re.sub('\\_com.*', '', target)\n",
    "                target = target+'_com'\n",
    "                instance.append(target)\n",
    "                usage.append(h[0])\n",
    "                timestamps.append(h[1])\n",
    "        else:\n",
    "            instance.append(np.nan)\n",
    "            usage.append(np.nan)\n",
    "            timestamps.append(np.nan)\n",
    "    df = pd.DataFrame({'instance': instance, 'usage':usage, 'timestamp':timestamps})\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading cpu logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from = './logs/cpu'\n",
    "save_to = './dataframes/'\n",
    "pathlist = Path(load_from).glob('*.json')\n",
    "df_cpu = pd.DataFrame()\n",
    "for p in pathlist:\n",
    "    jsonData = loadJson(p)\n",
    "    dayDF = getData(jsonData)\n",
    "    df_cpu = df_cpu.append(dayDF)\n",
    "    saveDataFrame(df_cpu,path=save_to+'cpu.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading network in logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from = './logs/network/inb'\n",
    "save_to = './dataframes/'\n",
    "pathlist = Path(load_from).glob('*.json')\n",
    "df_nwin = pd.DataFrame()\n",
    "for p in pathlist:\n",
    "    jsonData = loadJson(p)\n",
    "    dayDF = getData(jsonData)\n",
    "    df_nwin = df_nwin.append(dayDF)\n",
    "    saveDataFrame(df_nwin,path=save_to+'nwin.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading network out logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from = './logs/network/outb'\n",
    "save_to = './dataframes/'\n",
    "pathlist = Path(load_from).glob('*.json')\n",
    "df_nwout = pd.DataFrame()\n",
    "for p in pathlist:\n",
    "    jsonData = loadJson(p)\n",
    "    dayDF = getData(jsonData)\n",
    "    df_nwout = df_nwout.append(dayDF)\n",
    "    saveDataFrame(df_nwout,path=save_to+'nwout.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty fields\n",
    "df_cpu_clean = df_cpu.dropna(axis=0, how='all',subset=['instance','usage','timestamp'])\n",
    "df_nwin_clean = df_nwin.dropna(axis=0, how='all',subset=['instance','usage','timestamp'])\n",
    "df_nwout_clean = df_nwout.dropna(axis=0, how='all',subset=['instance','usage','timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all 3 dataframes\n",
    "cpu_nwin = pd.merge(df_cpu_clean, df_nwin_clean, how='inner', on= ['instance','timestamp'], suffixes=['_cpu','_nwin'])\n",
    "logData = pd.merge(cpu_nwin, df_nwout_clean, how='inner', on= ['instance','timestamp'])\n",
    "\n",
    "# rename to usage nwout\n",
    "logData.rename(columns={'usage': 'usage_nwout'}, inplace=True) \n",
    "\n",
    "# create readable date column from timestamp\n",
    "logData['date'] = logData.timestamp.apply(lambda x: datetime.datetime.fromtimestamp(x).strftime('%Y-%m-%d %X'))\n",
    "\n",
    "# clean instance name\n",
    "logData.instance = logData.instance.apply(lambda x: re.sub(r'.+EC2.','', x))\n",
    "logData.instance = logData.instance.apply(lambda x: re.sub('_','.', x))\n",
    "\n",
    "# reorder\n",
    "logData = logData[['instance', 'timestamp', 'date', 'usage_cpu', 'usage_nwin', 'usage_nwout']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add to historic log data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './dataframes/historicLogData.csv'\n",
    "historic = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# in case we are adding data we already added (drop it)\n",
    "historic = pd.concat([historic, logData]).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historic.to_csv(path, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove already used logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Was getting an error because .DS_store already exists so I am going to delete it everytime\n",
    "\n",
    "path = './used_logs/'\n",
    "for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "    for file in filenames:\n",
    "        if file=='.DS_Store':\n",
    "            os.remove(dirpath+'/'+file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Move used cpu logs\n",
    "source = './logs/cpu/'\n",
    "dest = './used_logs/cpu/'\n",
    "files = os.listdir(source)\n",
    "\n",
    "for f in files:\n",
    "    if f!='used':\n",
    "        shutil.move(source+f, dest+f)  #need to include +f because need exact path+filename when path already exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Move used nwin logs\n",
    "source = './logs/network/inb/'\n",
    "dest = './used_logs/network/inb/'\n",
    "files = os.listdir(source)\n",
    "\n",
    "for f in files:\n",
    "    if f!='used':\n",
    "        shutil.move(source+f, dest+f)    \n",
    "        \n",
    "#     print(source+f)\n",
    "#         shutil.move(source+f, dest+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move used nwout logs\n",
    "source = './logs/network/outb/'\n",
    "dest = './used logs/network/outb/'\n",
    "files = os.listdir(source)\n",
    "\n",
    "for f in files:\n",
    "        if f!='used':\n",
    "        shutil.move(source+f, dest+f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at data range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of records\n",
    "len(historic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of instances we have log data for\n",
    "# 373 because of nan\n",
    "len(historic.instance.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of instances we have log data for\n",
    "len(df_cpu_clean.instance.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of instances we have log data for\n",
    "len(df_nwin_clean.instance.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of instances we have log data for\n",
    "len(df_nwout_clean.instance.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date range\n",
    "aux = historic.sort_values(by='timestamp', ascending=False)\n",
    "aux = aux.reset_index(drop=True)\n",
    "\n",
    "dlast = aux.timestamp[0]\n",
    "dfirst = aux.timestamp[len(aux.timestamp)-1]\n",
    "days_range = (dlast-dfirst)/(3600*24)\n",
    "days_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('start date:', datetime.datetime.fromtimestamp(dfirst).strftime('%Y-%m-%d %X'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('last included date:', datetime.datetime.fromtimestamp(dlast).strftime('%Y-%m-%d %X'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to access a field (first column then row)\n",
    "# df['instance'][87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_from = \"./logs/cpu/cpu_1.json\"\n",
    "# with open(load_from,'r') as fp: \n",
    "#         data_json = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(data_json)):\n",
    "#     if data_json[i]!= []:\n",
    "#         print(data_json[i][0]['datapoints'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Same as above but trying to input it in a Dataframe directly\n",
    "# def getData(l):\n",
    "#     df = pd.DataFrame()\n",
    "#     df['instance'] = np.NaN\n",
    "#     df['usage'] = np.NaN\n",
    "#     df['timestamp'] = np.NaN\n",
    "#     for t in l:\n",
    "#         if t != []:\n",
    "#             usage = []\n",
    "#             timestamps = []\n",
    "#             idata = t[0]\n",
    "#             df['instance'] = idata['target']*len(idata['datapoints'])\n",
    "#             for h in (idata['datapoints']):\n",
    "#                 usage.append(h[0])\n",
    "#                 timestamps.append(h[1])\n",
    "#             df['usage'] = usage\n",
    "#             df['timestamp'] = timestamps\n",
    "#     return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different test i did\n",
    "\n",
    "# def getData(l):\n",
    "#     instance = []\n",
    "#     usage = []\n",
    "#     timestamps = []\n",
    "#     for t in l:\n",
    "#         if t != []:\n",
    "#             usage = []\n",
    "#             timestamps = []\n",
    "#             idata = t[0]\n",
    "#             instance = idata['target']\n",
    "#             for h in (idata['datapoints']):\n",
    "#                 usage.append(h[0])\n",
    "#                 timestamps.append(h[1])\n",
    "#         c = [instance, usage, timestamps]\n",
    "#     return (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Same as above but trying to input it in a Dataframe directly\n",
    "# def getData(l):\n",
    "# #     df = pd.DataFrame()\n",
    "# #     df['instance'] = np.NaN\n",
    "# #     df['usage'] = np.NaN\n",
    "# #     df['timestamp'] = np.NaN\n",
    "#     instance = []\n",
    "#     usage = []\n",
    "#     timestamps = []\n",
    "    \n",
    "#     for t in l:\n",
    "#         if t != []:\n",
    "# #             instance = []\n",
    "# #             usage = []\n",
    "# #             timestamps = []\n",
    "#             idata = t[0]\n",
    "#             #df['instance'] = idata['target']*len(idata['datapoints'])\n",
    "#            # instance.append(idata['target']*len(idata['datapoints']))\n",
    "#             for h in (idata['datapoints']):\n",
    "#                 instance.append(idata['target'])\n",
    "#                 usage.append(h[0])\n",
    "#                 timestamps.append(h[1])\n",
    "#             #df['usage'] = usage\n",
    "#             #df['timestamp'] = timestamps\n",
    "# #     df['instance'] = instance\n",
    "# #     df['usage'] = usage\n",
    "# #     df['timestamp'] = timestamps        \n",
    "# #     df = pd.concat([instance, usage, timestamps], axis=1)    \n",
    "# #    print(len(instance),len(usage), len(timestamps))\n",
    "#         else:\n",
    "#             instance.append([])\n",
    "#             usage.append([])\n",
    "#             timestamps.append([])\n",
    "#     df = pd.DataFrame({'instance': instance, 'usage':usage, 'timestamp':timestamps})\n",
    "#     return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regex tests\n",
    "# target = data_json[87][0]['target']\n",
    "# instance = re.sub('\\_com.*', '', target)\n",
    "# instance = instance+'.com'\n",
    "# instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tests for date\n",
    "# ts = logData.timestamp[0]\n",
    "# ts2 = logData.timestamp[1]\n",
    "\n",
    "\n",
    "# readable = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %X')\n",
    "# readable2 = datetime.datetime.fromtimestamp(ts2).strftime('%Y-%m-%d %X')\n",
    "# #.isoformat()\n",
    "# # datetime.datetime.strptime(readable, '%Y\n",
    "# datetime.datetime.strptime(readable2)-datetime.datetime.strptime(readable2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more regex testing\n",
    "# e = 'DEV0.domain.CSSAPPS.infra_service.EC2.cssapps001_da_aws_cccis_com'\n",
    "# e = re.sub(r'.+EC2.','',e)\n",
    "# e = re.sub('_', '.', e)\n",
    "# e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "# d2 = {'col1': [8, 2], 'col2': [9, 4]}\n",
    "# a = pd.DataFrame(data=d)\n",
    "# b = pd.DataFrame(data=d2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = pd.concat([a,b]).drop_duplicates().reset_index(drop=True)\n",
    "# m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
